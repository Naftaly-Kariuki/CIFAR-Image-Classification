{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4fabe9-d67b-47bf-b2c9-1a0ff2f24c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16409aa1-cb08-4291-a0ea-78bda4cb82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad20866-24f9-4911-91af-82ba6d571e85",
   "metadata": {},
   "source": [
    "#### using image size 96x96 as MobileNetV2 doesnt work well with smaller images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f12f5c8-6e70-4625-8479-b1cba39faa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 96\n",
    "\n",
    "x_train_full_resized = tf.image.resize(x_train_full, (image_size, image_size)).numpy().astype('float32')\n",
    "x_test_resized = tf.image.resize(x_test, (image_size, image_size)).numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781f4a10-6fb5-4311-879b-517908b49d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resized, x_val_resized, y_train, y_val = train_test_split(x_train_full_resized, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59753066-f271-4dfa-9126-494d241f5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_resized /= 255.0\n",
    "x_val_resized /= 255.0\n",
    "x_test_resized /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816531a9-4359-4a17-8946-b2b3bcacb26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99a34e-a8ce-49d6-8181-7f985bc0e33f",
   "metadata": {},
   "source": [
    "#### consistently ran out of memory on my GPU, had to resort to using CPU at the cost of speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097d030c-3fcd-4dd4-ba43-560e2c7fe88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000  \n",
    "batch_size = 64  \n",
    "\n",
    "# Training Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_resized, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=buffer_size).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Validation Dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val_resized, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Testing Dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_resized, y_test))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0bf729-e3b5-4b5f-959f-32d1a6c77cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(input_shape=(image_size, image_size, 3), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f770dfef-2634-4d83-aa39-fe6ef836c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bccdc09-7cb7-4e17-8a0a-b5ddd658a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d775b3d-e9f5-4fae-8060-da2d27d0f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccaf6be9-7693-484e-8ed2-f147dc6a044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cdc19d4-dcfa-4c9a-8861-6bc7d4515fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c134f-4264-40be-80e8-60d20f9adb20",
   "metadata": {},
   "source": [
    "#### Had the model set for 20 epochs but it started overfitting at around the 15th epoch. \n",
    "\n",
    "### An accuracy of 79.7% on the test dataset is still decent without finetuning an uplift of 10% from the 70% accuracy that I got on the basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36d92489-5d2b-4e8e-99a1-5e84b673e0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 262ms/step - accuracy: 0.5049 - loss: 1.5077 - val_accuracy: 0.7515 - val_loss: 0.7702 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 258ms/step - accuracy: 0.6761 - loss: 0.9387 - val_accuracy: 0.7622 - val_loss: 0.6975 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 259ms/step - accuracy: 0.6977 - loss: 0.8722 - val_accuracy: 0.7721 - val_loss: 0.6763 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 258ms/step - accuracy: 0.7073 - loss: 0.8374 - val_accuracy: 0.7810 - val_loss: 0.6613 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 259ms/step - accuracy: 0.7125 - loss: 0.8190 - val_accuracy: 0.7830 - val_loss: 0.6473 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 261ms/step - accuracy: 0.7209 - loss: 0.8059 - val_accuracy: 0.7854 - val_loss: 0.6436 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 273ms/step - accuracy: 0.7271 - loss: 0.7853 - val_accuracy: 0.7898 - val_loss: 0.6291 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 266ms/step - accuracy: 0.7237 - loss: 0.7893 - val_accuracy: 0.7876 - val_loss: 0.6144 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 267ms/step - accuracy: 0.7282 - loss: 0.7803 - val_accuracy: 0.7876 - val_loss: 0.6230 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 265ms/step - accuracy: 0.7300 - loss: 0.7636 - val_accuracy: 0.7935 - val_loss: 0.6151 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 264ms/step - accuracy: 0.7354 - loss: 0.7628 - val_accuracy: 0.7911 - val_loss: 0.6096 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 295ms/step - accuracy: 0.7385 - loss: 0.7497 - val_accuracy: 0.7944 - val_loss: 0.5907 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 286ms/step - accuracy: 0.7403 - loss: 0.7531 - val_accuracy: 0.8016 - val_loss: 0.6062 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 286ms/step - accuracy: 0.7452 - loss: 0.7407 - val_accuracy: 0.7968 - val_loss: 0.6060 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 282ms/step - accuracy: 0.7433 - loss: 0.7374 - val_accuracy: 0.7958 - val_loss: 0.6030 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=20,\n",
    "                    callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b73f9c-07cd-48fd-9e2c-f9ddbd762c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 208ms/step - accuracy: 0.7988 - loss: 0.5936\n",
      "Test Loss: 0.5948, Test Accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b92650-6881-4213-b36f-0a437e56f3e6",
   "metadata": {},
   "source": [
    "#### Unfreezing the last 4 layers of the model and reducing the learning improves the accuracy on the test dataset to 83.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02f44fce-642e-4a94-a8d9-bcdf25c55925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 254ms/step - accuracy: 0.7292 - loss: 0.9125 - val_accuracy: 0.7884 - val_loss: 0.6436 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 267ms/step - accuracy: 0.7662 - loss: 0.6798 - val_accuracy: 0.8090 - val_loss: 0.5720 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 262ms/step - accuracy: 0.7871 - loss: 0.6181 - val_accuracy: 0.8220 - val_loss: 0.5344 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 277ms/step - accuracy: 0.7998 - loss: 0.5764 - val_accuracy: 0.8272 - val_loss: 0.5158 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 277ms/step - accuracy: 0.8130 - loss: 0.5431 - val_accuracy: 0.8313 - val_loss: 0.5031 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 282ms/step - accuracy: 0.8165 - loss: 0.5263 - val_accuracy: 0.8335 - val_loss: 0.4930 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 278ms/step - accuracy: 0.8265 - loss: 0.4905 - val_accuracy: 0.8359 - val_loss: 0.4834 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 277ms/step - accuracy: 0.8312 - loss: 0.4828 - val_accuracy: 0.8402 - val_loss: 0.4798 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 278ms/step - accuracy: 0.8396 - loss: 0.4651 - val_accuracy: 0.8372 - val_loss: 0.4756 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 278ms/step - accuracy: 0.8438 - loss: 0.4451 - val_accuracy: 0.8398 - val_loss: 0.4725 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "finetuned_model = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=10,\n",
    "                    callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee2952d-bedd-4e2b-bcdd-0e62e8381a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.8371 - loss: 0.4836\n",
      "Test Loss: 0.4814, Test Accuracy: 0.8380\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18cfe8-776a-4cdd-806e-88ab1340d51d",
   "metadata": {},
   "source": [
    "#### With more compute power and time, I would unfreeze more layers as well as introduce data augmentation. I believe this would push the accuracy to more than 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6da182-f48a-4f32-9123-e69354e3cf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ISLP)",
   "language": "python",
   "name": "islp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
